
 <!DOCTYPE HTML>
<html lang="zh-cn">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <meta name="baidu_union_verify" content="d1952c66cf48912e21c18c7c581f382a">
  <meta name="360-site-verification" content="67fbcc5a67f4c65c057315b28fa0b2c8" />
<meta name="google-site-verification" content="2GzxQ0VtXwTSUdmGm6DzcmhTzM_I9QmzCb_pzpMzD88" />
  
    <title>Neural Network for Machine Learning Note (1) | Sponge No.43</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="Chan Zou">
    
    <meta name="description" content="NN ArchitechuresNNs can be roughly divided into 3 groups based on their architechures.
Feed-Foward NNArchitechure of feed-forward nn is straightforwar">
    
    
    
    
    <link rel="alternate" href="atom.xml" title="Sponge No.43" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/ChanZou.ico">
    
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
    
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            var _bdId ='315597da49e436164821a87f3757ef4f';
             hm.src = "//hm.baidu.com/hm.js?" + _bdId;
             var s = document.getElementsByTagName("script")[0]; 
             s.parentNode.insertBefore(hm, s);
        })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
      
</head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header>
      <div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Sponge No.43">Sponge No.43</a></h1>
				<a class="blog-motto"></a>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜單">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/tags">标签</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
					
                                            <form class="search" action=http://zhannei.baidu.com/cse/search target="_blank">
                                            <label>Search</label>
                                        <input name="s" type="hidden" value= null ><input type="text" name="q" size="30" placeholder="搜索"><br>
					
					</li>
				</ul>
                            </nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/01/16/2016011601/" title="Neural Network for Machine Learning Note (1)" itemprop="url">Neural Network for Machine Learning Note (1)</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://yoursite.com" title="Chan Zou">Chan Zou</a>
    </p>
  <p class="article-time">
    <time datetime="2016-01-16T20:00:00.000Z" itemprop="datePublished">2016-01-16</time>
    更新日期:<time datetime="2018-02-19T00:07:16.281Z" itemprop="dateModified">2018-02-18</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目錄</strong>
		<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#NN_Architechures"><span class="toc-number">1.</span> <span class="toc-text">NN Architechures</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Feed-Foward_NN"><span class="toc-number">1.1.</span> <span class="toc-text">Feed-Foward NN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recurrent_NN"><span class="toc-number">1.2.</span> <span class="toc-text">Recurrent NN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Symmetric_Connected_NN"><span class="toc-number">1.3.</span> <span class="toc-text">Symmetric Connected NN</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Perceptron"><span class="toc-number">2.</span> <span class="toc-text">Perceptron</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Details_about_Learning_Procedure"><span class="toc-number">2.1.</span> <span class="toc-text">Details about Learning Procedure</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gemetrical_view"><span class="toc-number">2.2.</span> <span class="toc-text">Gemetrical view</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Limitation"><span class="toc-number">2.3.</span> <span class="toc-text">Limitation</span></a></li></ol></li></ol>
		</div>
		
		<h2 id="NN_Architechures">NN Architechures</h2><p>NNs can be roughly divided into 3 groups based on their architechures.</p>
<h3 id="Feed-Foward_NN">Feed-Foward NN</h3><p>Architechure of feed-forward nn is straightforward and is shown below.<br><img src="http://ww4.sinaimg.cn/large/7446635dgw1f01yyifd4cj20jw0c6q47.jpg" alt="&#39;Feed-Forward NN&#39;{50*50}"></p>
<h3 id="Recurrent_NN">Recurrent NN</h3><p>In recurrent nn, units may be connected to others whithin the same layer. These have directed cycle in their connect and therefore have complicated dynamics and could be very difficult to train.<br><img src="http://ww1.sinaimg.cn/large/7446635dgw1f01z0k5bvrj20ak0b2q3j.jpg" alt="&#39;Recurrent NN&#39;"><br> But their architechure renders them ability to keep an ‘internal state’. As the result, they are a very natural way to model sequential data. In fact, they are equivalent to very deep nets with one hidden layer per time slice.<br><img src="http://ww3.sinaimg.cn/large/7446635dgw1f01z1x6bolj20f40muq4r.jpg" alt="&#39;Sequential Procedure&#39;"></p>
<h3 id="Symmetric_Connected_NN">Symmetric Connected NN</h3><p>Still, we have an ‘easy-version’ of recurrent nn. They are like recurrent networks, but connections between units are symmetrical. Because they obey energy function so cycles are not allowed to exist. Given these additional restrictions, symmetric connected nns are easier to analyze.</p>
<h2 id="Perceptron">Perceptron</h2><p>Perceptron is the first generation of neural network. It converts input vectors into vectors of feature activations. Its standard architecture looks like this:<br><img src="http://ww4.sinaimg.cn/large/7446635dgw1f01zijjfslj20k20i4jtl.jpg" alt="&#39;Standard Perceptron&#39;"><br>Its learning procedure is to adjust weight of each feature activation. If the quantity is above some threshold, it decides that the input vector is a positive example. (The threshold is equivalent to negative bias.)</p>
<h3 id="Details_about_Learning_Procedure">Details about Learning Procedure</h3><ul>
<li>If the output unit is correct, leave its weights alone</li>
<li>If the output unit incorrectly outputs a 0, add the input vector to the weight vector.</li>
<li>If the output unit incorrectly outputs a 1, substract the input vector from the weight vector.</li>
</ul>
<p>The good news is, this is guaranteed to find a set of weights that is right answer to all training cases <em>If it exists</em>. (Many don’t, sadly.)</p>
<h3 id="Gemetrical_view">Gemetrical view</h3><p>In a weight space, a point represents a particular set of weight and a hyperplane represent an input case. Input vectors are the normals of hyperplanes.<br><img src="http://ww1.sinaimg.cn/large/7446635dgw1f0207gyz3lj20pw0l4mzi.jpg" alt=""><br>Given every training case, the weight pointer either hold still (when output is correct) or move towards ‘the right side’. Furthermore, with the help pf the concept ‘generously feasible weight vector’, we can prove that after a finite number of mistakes, the wieght vector must lie in the feasible region (another name: cone) if this region exists. </p>
<h3 id="Limitation">Limitation</h3><p>If allowed to choose the features by hand and use enough features, we can do almost everything with perceptron. But this kind of ‘look-up’ mechanism won’t generalize.<br>Consider data space in which particular set of weights is a plane and each input is a point. What if points cannot be seperated into groups correctly by a plane? Then perceptron won’t help in this case.</p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/MOOCs/">MOOCs</a><a href="/tags/Neural-Network/">Neural Network</a>
  </div>




<div class="article-share" id="share">

  <div data-url="http://yoursite.com/2016/01/16/2016011601/" data-title="Neural Network for Machine Learning Note (1) | Sponge No.43" data-tsina="1950770013" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2016/01/17/2016011602/" title="Neural Network for Machine Learning Note (2)">
  <strong>PREVIOUS:</strong><br/>
  <span>
  Neural Network for Machine Learning Note (2)</span>
</a>
</div>


<div class="next">
<a href="/2015/08/15/2015081501/"  title="Linear Model Selection and Regularization">
 <strong>NEXT:</strong><br/> 
 <span>Linear Model Selection and Regularization
</span>
</a>
</div>

</nav>

	
<section class="comment">
	
	<div class="ds-thread" data-title="Neural Network for Machine Learning Note (1)" data-thread-key="2016011601" data-author-key="Chan Zou" data-url="http://yoursite.com/post/2016011601"></div>
	
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="顯示側邊欄"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目錄</strong>
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#NN_Architechures"><span class="toc-number">1.</span> <span class="toc-text">NN Architechures</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Feed-Foward_NN"><span class="toc-number">1.1.</span> <span class="toc-text">Feed-Foward NN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recurrent_NN"><span class="toc-number">1.2.</span> <span class="toc-text">Recurrent NN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Symmetric_Connected_NN"><span class="toc-number">1.3.</span> <span class="toc-text">Symmetric Connected NN</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Perceptron"><span class="toc-number">2.</span> <span class="toc-text">Perceptron</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Details_about_Learning_Procedure"><span class="toc-number">2.1.</span> <span class="toc-text">Details about Learning Procedure</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gemetrical_view"><span class="toc-number">2.2.</span> <span class="toc-text">Gemetrical view</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Limitation"><span class="toc-number">2.3.</span> <span class="toc-text">Limitation</span></a></li></ol></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隱藏側邊欄"></a></div>
<aside class="clearfix">
<div id="authorInfo">
	
		<div class="author-logo"></div>		
	
	<div class="social-list" class="clearfix">
		
		<a href="http://weibo.com/1950770013" target="_blank" title="weibo"></a>
		
		
		
		<a href="https://github.com/chanzou" target="_blank" title="github"></a>
		
		
		
		<a href="https://zhihu.com/people/chanzou" target="_blank" title="zhihu"></a>
		
	</div>
</div>

  

  
<div class="tagslist">
	<p class="asidetitle">標簽</p>
		<ul class="clearfix">
		
			<li><a href="/tags/Algorithm/" title="Algorithm">Algorithm<sup>2</sup></a></li>
		
			<li><a href="/tags/Data-Structure/" title="Data Structure">Data Structure<sup>2</sup></a></li>
		
			<li><a href="/tags/HDL/" title="HDL">HDL<sup>1</sup></a></li>
		
			<li><a href="/tags/Hadoop/" title="Hadoop">Hadoop<sup>1</sup></a></li>
		
			<li><a href="/tags/MOOCs/" title="MOOCs">MOOCs<sup>7</sup></a></li>
		
			<li><a href="/tags/Neural-Network/" title="Neural Network">Neural Network<sup>8</sup></a></li>
		
			<li><a href="/tags/Statistics/" title="Statistics">Statistics<sup>3</sup></a></li>
		
			<li><a href="/tags/hexo/" title="hexo">hexo<sup>3</sup></a></li>
		
			<li><a href="/tags/spider/" title="spider">spider<sup>1</sup></a></li>
		
			<li><a href="/tags/spiders/" title="spiders">spiders<sup>2</sup></a></li>
		
			<li><a href="/tags/travel/" title="travel">travel<sup>1</sup></a></li>
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情鏈接</p>
    <ul>
      <li><a href="http://hexo.io" target="_blank" title="Hexo">Hexo</a></li>
      <li><a href="http://gengbiao.me" target="_blank" title="coney">coney's Blog</a></li>
    </ul>
</div>


  <div class="rsspart">
	<a href="atom.xml" target="_blank" title="rss">RSS 訂閱</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
    
            <p class="copyright"> © 2018 
		
		<a href="http://yoursite.com" target="_blank" title="Chan Zou">Chan Zou</a>
		
            && Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> && Theme by <a href="http://gengbiao.me" target="_blank" title="coney">coney</a>
            </div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>


<script type="text/javascript">
  var duoshuoQuery = {short_name:"chan"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 









<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'null', 'null');  
ga('send', 'pageview');
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  </body>
</html>

